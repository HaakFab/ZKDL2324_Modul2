{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Librarian - Modul 2 PyTerrier Tutorial\n",
    "## This notebook is based on a CIKM workshop\n",
    "https://github.com/terrier-org/cikm2021tutorial/blob/main/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn more about pyterrier: https://pyterrier.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install pyterrier\n",
    "%pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"artificial intelligence\"\n",
    "url =  f\"https://www.bibsonomy.org/json/search/{query}?items=1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai = pd.DataFrame(data[\"items\"])\n",
    "df_ai = df_ai[df_ai[\"type\"] == \"Publication\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops columns where at least 50% of the rows have missing values\n",
    "df_ai_filtered = df_ai.dropna(axis=1, thresh=len(df_ai)*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets only use columns which seems useful for us\n",
    "useful_coulmns = ['id', 'tags', 'label', 'description', 'date', 'changeDate', 'url', 'pub-type', 'year', 'author', 'authors', 'publisher']\n",
    "df_ai_filtered = df_ai_filtered[useful_coulmns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise pyterrier\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyterrier exspects a docno field\n",
    "df_ai_filtered['docno'] = df_ai_filtered['id']\n",
    "df_ai_filtered['text'] = df_ai_filtered['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excursus indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we start to index our data\n",
    "#more details at https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html\n",
    "\n",
    "index_folder = \"./ai_index\"\n",
    "\n",
    "indexer = pt.DFIndexer(index_folder, overwrite=True)\n",
    "index_ref = indexer.index(df_ai_filtered['text'], df_ai_filtered['docno'])\n",
    "\n",
    "print(f\"path to our index: {index_ref.toString()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our index\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term -> term_id Nt Tf\n",
    "#Nt: In how many documents does the term occur\n",
    "#TF: How often does the term occur in total\n",
    "\n",
    "for kv in index.getLexicon():\n",
    "    print(f\"{kv.getKey()} -> {kv.getValue().toString()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"game\"\n",
    "index.getLexicon()[term].toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how often do the terms occur\n",
    "term_freq_dict = {}\n",
    "\n",
    "for kv in index.getLexicon():\n",
    "    term_freq_dict[kv.getKey()] = kv.getValue().frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort all terms from the index in descending order \n",
    "term_freq_dict_sorted = sorted(term_freq_dict.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the 30 nost popular entries\n",
    "top_k = 30\n",
    "term_freq_dict_sorted[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our search engine\n",
    "search_engine = pt.BatchRetrieve(index, wmodel=\"Tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.search(\"system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the `search()` method returns a dataframe with columns:\n",
    " - `qid`: this is by default \"1\", since it's our first and only query\n",
    " - `docid`: Terrier' internal integer for each document\n",
    " - `docno`: the external (string) unique identifier for each document\n",
    " - `score`: since we use the `Tf` weighting model, this score corresponds the total frequency of the query (terms) in each document\n",
    " - `rank`: A handy attribute showing the descending order by score\n",
    " - `query`: the input query\n",
    "\n",
    "As expected, the `Tf` weighting model used here only counts the frequencies of the query terms in each document, i.e.:\n",
    "$$\n",
    "score(d,q) = \\sum_{t \\in q} tf_{t,d}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.search(\"intelligent education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what do we need for the inverse document frequency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem the term its base form\n",
    "stem = stemmer.stem(\"learning\")\n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in how many documents does the stem 'learn' occur?\n",
    "lexicon = index.getLexicon()\n",
    "lexicon[stem].getDocumentFrequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many documents occur in our index?\n",
    "index.getCollectionStatistics().numberOfDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_for_term(term, index):\n",
    "  lex = index.getLexicon()\n",
    "  stemmed_term = stemmer.stem(term)\n",
    "\n",
    "  if not stemmed_term in lex:\n",
    "    return \n",
    "    \n",
    "  lex_entry = lex[stemmed_term]\n",
    "\n",
    "  df_term = lex_entry.getDocumentFrequency()\n",
    "  N = index.getCollectionStatistics().numberOfDocuments\n",
    "  \n",
    "  #inverse document frequency\n",
    "  idf = N/df_term\n",
    "\n",
    "  #apply logarithm(base 10) to idf\n",
    "  log_idf = np.emath.logn(10, idf)\n",
    "\n",
    "  return log_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_idf_for_term(\"learning\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your own tf_idf method here:\n",
    "\n",
    "def calc_tf_idf(query, docno, index):\n",
    "    #remember that tfidf is the product of two components\n",
    "    #hint: the tf model search result contains tf frequencies\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"intelligent education\"\n",
    "docno = \"https://www.bibsonomy.org/bibtex/201f2eb94f27fe662c37249be37619d8b/dblp\"\n",
    "\n",
    "print(f\"The tf-idf for query: {query} and document: {docno} is {calc_tf_idf(query, docno, index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine_tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine_tfidf.search(\"intelligent education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we want to build an index with multiple fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfrom dataframe into list of dictionaries\n",
    "ai_dict = df_ai_filtered.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_folder_mult = \"./ai_index_mult\"\n",
    "\n",
    "fields=['docno', 'text', 'tags', 'description']\n",
    "\n",
    "indexer_mult = pt.IterDictIndexer(index_folder_mult, meta={'docno': 200, 'text': 4096}, overwrite=True)\n",
    "index_ref_mult = indexer_mult.index(ai_dict, fields=fields)\n",
    "\n",
    "print(f\"path to our index: {index_ref_mult.toString()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mult = pt.IndexFactory.of(index_ref_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index_mult.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine_mult = pt.BatchRetrieve(index_mult, wmodel=\"TF_IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = search_engine_mult.search(\"intelligence\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our data\n",
    "pickle.dump(df_ai_filtered, open(\"workspace/ai_publications.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
